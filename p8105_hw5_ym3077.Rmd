---
title: "p8105_hw5_ym3077"
output: github_document
---

Load package
```{r}
library(tidyverse)
library(broom)
set.seed(1)
```


## Problem 1

Write a function that simulates birthdays and checks for duplicates
```{r}
bday_sim = function(n_people) {
  
  birthdays = sample(1:365, size = n_people, replace = TRUE)

  repeated_bday = length(unique(birthdays)) < n_people

  repeated_bday
  
}
```

Run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. 
```{r}
bday_results = 
  expand_grid(
    group_size = 2 :50,
    iter = 1:1000) |>
  mutate(share_bday = map_lgl(group_size, bday_sim)) |>
  group_by(group_size) |>
  summarize(prob_sharebday = mean(share_bday))
  
```

Make a plot showing the probability as a function of group size, and comment on your results.
```{r}
bday_results |> 
  ggplot(aes(x = group_size, y = prob_sharebday)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Probability of Shared Birthday vs. Sample Size",
    x = "Number of People in the Room",
    y = "Probability of more than 1 Shared Birthday"
  ) +
  theme_minimal()
```
    
This plot shows the estimated probability of at least 2 people in a group share the same birthday, for group sizes varying from 2 to 50. The probability is very low for small groups (less than 5), and rises rapidly for groups with 15-30 people, finally approaches to 1 as the group size nears 50. 
    
    
## Problem 2

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value ofùúáon the x axis. Describe the association between effect size and power.

Function Set up and Run 5000 simulations for Œº = 0,1,2,3,4,5,6
```{r}
n = 30
sigma = 5
sim_one <- function(mu) {
  x <- rnorm(n = n, mean = mu, sd = sigma)
  ttest <- t.test(x, mu = 0)
  tidy(ttest) |>
    select(estimate, p.value) |>
    rename(mu_hat = estimate) 
}

sim_results <-
  expand_grid(
    true_mu = 0:6,
    iter = 1:5000) |>
  mutate(output = map(true_mu, sim_one)) |>
  unnest(output)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ùúá on the x axis. Describe the association between effect size and power.
```{r}
power_df <-
  sim_results |>
  group_by(true_mu) |>
  summarize(power = mean (p.value <0.5)) |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_point() +
  geom_line() +
  labs( titble = "Power of One-Sample T-Test",
        x = "True mean (Œº)",
        y = "Power: Proportion of times reject H0"
  )
power_df
```
    
The plot shows power increases as the true mean (Œº) increases. Since the H0: Œº = 0, and population standard deviation is fixed at 5, as true mean (Œº) increases to 1, 2, 3 and higher, the effect size increases, the test is increasingly likely to detect the mean is not zero, and power rises sharply approaching to 1 for  Œº = 4.
    
    
Make a plot showing the average estimate of ùúáÃÇ on the y axis and the true value of ùúá on the x axis. 
```{r}
avg_est <- sim_results |>
  group_by(true_mu) |>
  summarize(avg_mu_hat = mean(mu_hat))

ggplot(avg_est, aes(x = true_mu, y = avg_mu_hat)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Œº vs. True mean (Œº)",
    x = "True mean (Œº)",
    y = "Average ŒºÃÇ")+
  theme_minimal()
```
    
Make a second plot (or overlay on the first) the average estimate of ùúáÃÇ only in samples for which the null was rejected on the y axis and the true value of ùúá
 on the x axis.
```{r}
avg_reject <-
  sim_results |>
  filter(p.value < 0.05) |>
  group_by(true_mu) |>
  summarize(mu_hat_reject = mean(mu_hat))

ggplot(avg_reject, aes(x = true_mu, y = mu_hat_reject)) +
  geom_point() +
  geom_line() +
  labs(
    title = " Average ŒºÃÇ when H0 is rejected",
    x = "True mean (Œº)",
    y = "Average ŒºÃÇ on rejected samples"
  ) +
  theme_minimal()

```
    
Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of ùúá? Why or why not?
No, according to the plot the sample average of Œº_hat among only the rejected samples is not equal to the true mean (Œº), especially when true mean (Œº) is small. Because rejecting H0 requires extreme estimates (sample mean to be far enough from 0) to produce a small p-value. As true mean (Œº) gets larger and the test has higher power, nearly all samples are included in the "rejecting" region, and all reject the null. 
    
    
## Problem 3

Upload the dataset.
```{r}
homicides <- 
  read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv")
```

Describe the raw data. Create a `city_state` variable (e.g. ‚ÄúBaltimore, MD‚Äù) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is ‚ÄúClosed without arrest‚Äù or ‚ÄúOpen/No arrest‚Äù).
```{r}
homicides_sum <- homicides |>
  mutate(city_state = str_c(city, "," , state),
         unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")) |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved),
    )
homicides_sum
```

The raw dataset contains `r nrow(homicides)` homicide records collected by The Washington Post from `r length(unique(homicides$city))` large U.S. cities. Each row orresponds to a single homicide case and includes detailed information on" uid, date, reported, victim demographics, the city and state, latitude/longitude, and the case disposition (solved or unsolved).
    
    
      
For the city of Baltimore, MD, use the `prop.test` function to estimate the proportion of homicides that are unsolved; save the output of `prop.test` as an R object, apply the `broom::tidy` to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
baltimore = homicides_sum |>
  filter(city_state == "Baltimore,MD")

baltimore_test =
  prop.test(
    x = baltimore$unsolved_homicides,
    n = baltimore$total_homicides
  )

baltimore_tidy = 
  tidy(baltimore_test) |>
  select(estimate, conf.low, conf.high)
  
baltimore_tidy
```
The estimated proportion of unsolved homicides in Baltimore, MD is 
`r round(baltimore_tidy$estimate, 3)` with a 95% CI of 
(`r round(baltimore_tidy$conf.low, 3)`, `r round(baltimore_tidy$conf.high, 3)`).
    
    
Now run `prop.test` for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. 
Do this within a ‚Äútidy‚Äù pipeline, making use of `purrr::map`, `purrr::map2`, list columns and `unnest` as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
city_prop = homicides_sum |>
  mutate(
    test = map2(unsolved_homicides, total_homicides, ~ prop.test(x = .x, n = .y)),
    tidy = map(test, broom::tidy)) |>
  select(city_state, tidy) |>
  unnest(tidy)
```
    
    
Create a plot that shows the estimates and CIs for each city ‚Äì check out `geom_errorbar` for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
```{r}
city_prop_plot = city_prop |>
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state)) |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(color = "red", size = 2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion Unsolved"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
city_prop_plot
```













