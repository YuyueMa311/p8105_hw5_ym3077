---
title: "p8105_hw5_ym3077"
output: github_document
---

Load package
```{r}
library(tidyverse)
library(broom)
set.seed(1)
```


## Problem 1

Write a function that simulates birthdays and checks for duplicates
```{r}
bday_sim = function(n_people) {
  
  birthdays = sample(1:365, size = n_people, replace = TRUE)

  repeated_bday = length(unique(birthdays)) < n_people

  repeated_bday
  
}
```

Run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. 
```{r}
bday_results = 
  expand_grid(
    group_size = 2 :50,
    iter = 1:1000) |>
  mutate(share_bday = map_lgl(group_size, bday_sim)) |>
  group_by(group_size) |>
  summarize(prob_sharebday = mean(share_bday))
  
```

Make a plot showing the probability as a function of group size, and comment on your results.
```{r}
bday_results |> 
  ggplot(aes(x = group_size, y = prob_sharebday)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Probability of Shared Birthday vs. Sample Size",
    x = "Number of People in the Room",
    y = "Probability of more than 1 Shared Birthday"
  ) +
  theme_minimal()
```
    
This plot shows the estimated probability of at least 2 people in a group share the same birthday, for group sizes varying from 2 to 50. The probability is very low for small groups (less than 5), and rises rapidly for groups with 15-30 people, finally approaches to 1 as the group size nears 50. 
    
    
## Problem 2

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value ofùúáon the x axis. Describe the association between effect size and power.

Function Set up and Run 5000 simulations for Œº = 0,1,2,3,4,5,6
```{r}
n = 30
sigma = 5
sim_one <- function(mu) {
  x <- rnorm(n = n, mean = mu, sd = sigma)
  ttest <- t.test(x, mu = 0)
  tidy(ttest) |>
    select(estimate, p.value) |>
    rename(mu_hat = estimate) 
}

sim_results <-
  expand_grid(
    true_mu = 0:6,
    iter = 1:5000) |>
  mutate(output = map(true_mu, sim_one)) |>
  unnest(output)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ùúá on the x axis. Describe the association between effect size and power.
```{r}
power_df <-
  sim_results |>
  group_by(true_mu) |>
  summarize(power = mean (p.value <0.5)) |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_point() +
  geom_line() +
  labs( titble = "Power of One-Sample T-Test",
        x = "True mean (Œº)",
        y = "Power: Proportion of times reject H0"
  )
power_df
```
    
The plot shows power increases as the true mean (Œº) increases. Since the H0: Œº = 0, and population standard deviation is fixed at 5, as true mean (Œº) increases to 1, 2, 3 and higher, the effect size increases, the test is increasingly likely to detect the mean is not zero, and power rises sharply approaching to 1 for  Œº = 4.
    
    
Make a plot showing the average estimate of ùúáÃÇ on the y axis and the true value of ùúá on the x axis. 
```{r}
avg_est <- sim_results |>
  group_by(true_mu) |>
  summarize(avg_mu_hat = mean(mu_hat))

ggplot(avg_est, aes(x = true_mu, y = avg_mu_hat)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Œº vs. True mean (Œº)",
    x = "True mean (Œº)",
    y = "Average ŒºÃÇ")+
  theme_minimal()
```
    
Make a second plot (or overlay on the first) the average estimate of ùúáÃÇ only in samples for which the null was rejected on the y axis and the true value of ùúá
 on the x axis.
```{r}
avg_reject <-
  sim_results |>
  filter(p.value < 0.05) |>
  group_by(true_mu) |>
  summarize(mu_hat_reject = mean(mu_hat))

ggplot(avg_reject, aes(x = true_mu, y = mu_hat_reject)) +
  geom_point() +
  geom_line() +
  labs(
    title = " Average ŒºÃÇ when H0 is rejected",
    x = "True mean (Œº)",
    y = "Average ŒºÃÇ on rejected samples"
  ) +
  theme_minimal()

```
    
Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of ùúá? Why or why not?
No, according to the plot the sample average of Œº_hat among only the rejected samples is not equal to the true mean (Œº), especially when true mean (Œº) is small. Because rejecting H0 requires extreme estimates (sample mean to be far enough from 0) to produce a small p-value. As true mean (Œº) gets larger and the test has higher power, nearly all samples are included in the "rejecting" region, and all reject the null. 

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
